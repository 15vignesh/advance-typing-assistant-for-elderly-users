{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585be9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.7.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb563f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f65df78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are numerous things required for the existence of the individual; food and nutrition is considered as one of the imperative aspects that are essential for the survival of the human being. An individual in his life implements number of tasks and duties, all the functions are effectively carried out by obtaining energy, vigor and strength and that one obtains through acquiring food and proper nutrition. Food is not only vital to carry out ones job duties, performing well academically or putting into operation the household chores and rendering an effective contribution in other activities such as physical exercises, music, dance, arts and crafts, sports and so forth; food is considered to be an essential requirement for ones normal growth and development. The intake of certain foods called nutrients influence the functions of the body, protect the body against diseases or illnesses, reinstate health and establish people’s responses to changes that occur within an environment. Food and nutrition assists an individual in forming a holistic and an integrated understanding of this composite, comprehensive and methodical area. Human nutrition takes into account the processes whereby cellular organelles, cells, tissues, organs, systems and the functioning of the human body make use of the required materials obtained from the foods to sustain structural and efficient uprightness. The main purpose of this research paper is to understand the concepts of food and nutrition and the relationship that they form with the health of the individual; the main areas are, understanding food and nutrition, functions of food, the essentials of the nutrients, food and nutrition in India, the relationship between food and nutrition and health, and the connection between food, nutrition, diet and non-communicable diseases. This research paper highlights the understanding that how an individual is able to acquire and make use of foods and nutrients from the molecular to the community level and the factors that are necessary in determining and influencing these processes; proper foods and nutrients contribute in the effective growth and development of the human body and enhances the quality of living standards. Keywords: Food, Nutrition, Health, Diet, Malnutrition, Nutrients Understanding Food and Nutrition Food has been considered to be an imperative part for the existence of a human being or any other living organism; in order to obtain a good health, to accomplish ones jobs and duties in an effective manner, to recover from illnesses, to implement adequate growth and development of the children and to survive, food is a basic necessity that is required to get fulfilled. Food is considered to be an extremely important topic in the articles, magazines, conversations and advertisements. Within a household, early in the morning when individuals wake up, they always seek what food to prepare for the day; when a person feels depressed or angry and he consumes his desirable food items, he feels relaxed, because relaxation of the mind takes place through consumption of comfort food; well prepared, delicious meals soothes the mindset of the person. Food, nutrition and health are considered to be crucial aspects of an individual’s life; food is that which nourishes the body, it can be anything which one can either eat or drink, which meets the requirements of energy, structure, directive and safeguarding of the body. Food is considered to be the raw material which makes up the bodies, food items are of different types and consumption of healthy and nutritious food ensures good health, personal appearance, effectiveness and emotional well being; the mindset of the individual remains peaceful and pacified when he consumes healthy and nutritious food (Foods, Nutrition and Health, n.d.). Nutrition is defined as when food performs its work within the body; nutrition includes everything that happens to the food from the time it is consumed until it is utilized for the performance of various functions within the body. Nutrients are constituents of food that are required by the body in sufficient amounts in order to nurture, reproduce and lead a standard, healthy life. Nutrients include water, proteins, fats, carbohydrates, minerals and vitamins. There are several nutrients in each of the groups, these are proteins, fats, carbohydrates, minerals and vitamins; hence the plural form of these words have been stated. Therefore, there are more than 40 essential nutrients supplied by food, which are used to produce accurately thousands of materials needed for an energetic living and good physical health (Foods, Nutrition and Health, n.d.). Nutritional status is the condition of the human body as an outcome of the foods consumed and their utilization by the body; nutritional status can be good quality, moderate or deprived. The features of a good quality nutritional status lead to a prepared, pleasant individuality and behavior, a strong and a robust body, and maintenance of normal body weight. An individual when obtains good nutritional status, always feels happy and is in a good mood, he becomes good natured and always treats others with respect and courtesy. General good health is apparent by determination for work, regular meal timings, sound regular sleep, regular eradication and struggle against any kinds of weaknesses and illnesses. Deprived and weak nutritional status is supported by a lethargic, uninterested and short-tempered personality traits, undersized inadequately developed body, the body weight is not normal, either it is too thin or fat or a sagging body, muscles become undersized and out of condition, with a pale skin color; obesity is one of the most severe problems that occur due to inadequate nutritional status and it leads to disfigurement, when an individual consumes unhealthy food items then it results in weight gain and in turn lead to obesity. Deprived nutritional status may be the effect of inappropriate selection of food items, consumption of food during inappropriate timings, working for long hours without eating, and having inadequate sleep (Foods, Nutrition and Health, n.d.). Functions of Food The food has been classified in accordance with the performance of their functions within the body, the functions of the food are considered to be important in the acceptance and planning of ones meals which are not only adequate in a nutritional manner but they are agreeable and make an individual feel comfortable: (Nutrition and Dietetics, 2004). Physiological Functions of Foods – The physiological functions of food are classified into three categories such as the energy yielding foods, body building foods and protective and regulatory foods. a) Energy Yielding Foods – Foods that are rich in carbohydrates and fats are termed as energy yielding foods, they make provision of energy to sustain the involuntary processes that are necessary for the existence of the human being. In order to carry out the daily life activities, an individual needs his adequate food consumption, for instance the activities and functions regarding the performance of professional, household and recreational activities requires energy and liveliness, therefore, in order to effectively accomplish these activities, one requires carbohydrate and fat enriched foods. The energy needed is supplied by the oxidation of the foods consumed; the foods that are considered to be good sources of energy are wheat, pulses, cereals, roots, tubers, dried fruits, oils, butter and ghee. b) Body Building Foods - Foods that are rich in protein are known as body building foods. Foods such as milk, meat, eggs and fish are rich in proteins of superior quality. Pulses and nuts are regarded to be good sources of protein but the protein is not of enhanced quality. These foods assist the individual in the maintenance of a good life and encourage effective growth and development; they also provide energy to the human body which is required for the performance of daily life activities. c) Protective and Regulatory Foods - Foods that are rich in protein, minerals and vitamins are known as protective and regulatory foods. They are vital for health and for regulation of activities and functions such as maintenance of the body temperature, muscle contraction, control of water balance, clotting of blood, removal of waste products from the body and maintaining heartbeat. Milk, egg, liver, fruits and vegetables are known as protective foods. Social Functions of Food - Food has always been an imperative part of the community, social, cultural and religious life; during the organization of any occasions or events such as marriages, religious functions or ceremonies, food is considered to be a vital aspect. It has been significance and an indication of togetherness, camaraderie and contentment at religious, community and family gatherings, occasions and festivals. Food is an integral part of an individual’s social existence, when friends and relatives make a visit then also the presence of food creates a jovial and a friendly atmosphere; during the occurrence of any festival, mostly food items are given to friends and relatives in the form of gifts such as cakes during Christmas. Psychological Functions of Food – Foods are considered vital in satisfying the emotional needs of the individuals as well, these include the sense of security, love and acceptance; for example, preparation of appetizing and delicious meals for the family members indicates admiration and warmth. Sharing of food with others is considered to be an indication of friendship and acceptance, for example, when children go to school, their mothers provide them delectable meals and always tell them to share their meals with their friends so that they are socially accepted and recognized; familiar and known foods provide security to an individual, whereas unfamiliar foods may be distasteful to an individual and he may not feel satisfie'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"nutrition.txt\", \"r\", encoding = \"utf8\")\n",
    "\n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines)\n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','').replace(',','').replace('.','.').replace(';','').replace(')','').replace('(','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces\n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fa91e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "The Length of sequences are:  4094\n",
      "Data:  [[ 79   9 449]\n",
      " [  9 449 450]\n",
      " [449 450  43]\n",
      " [450  43  19]\n",
      " [ 43  19   1]\n",
      " [ 19   1  87]\n",
      " [  1  87   3]\n",
      " [ 87   3   1]\n",
      " [  3   1  16]\n",
      " [  1  16   6]]\n",
      "Response:  [450  43  19   1  87   3   1  16   6   2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]\n",
    "len(sequence_data)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "\n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5abd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             10000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14060000 (53.63 MB)\n",
      "Trainable params: 14060000 (53.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033b3bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 6.1485\n",
      "Epoch 1: loss improved from inf to 6.14847, saving model to next_words.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 36s 436ms/step - loss: 6.1485\n",
      "Epoch 2/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.7846\n",
      "Epoch 2: loss improved from 6.14847 to 5.78457, saving model to next_words.h5\n",
      "64/64 [==============================] - 26s 399ms/step - loss: 5.7846\n",
      "Epoch 3/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.7205\n",
      "Epoch 3: loss improved from 5.78457 to 5.72047, saving model to next_words.h5\n",
      "64/64 [==============================] - 26s 400ms/step - loss: 5.7205\n",
      "Epoch 4/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.6727\n",
      "Epoch 4: loss improved from 5.72047 to 5.67272, saving model to next_words.h5\n",
      "64/64 [==============================] - 26s 402ms/step - loss: 5.6727\n",
      "Epoch 5/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.6430\n",
      "Epoch 5: loss improved from 5.67272 to 5.64298, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 5.6430\n",
      "Epoch 6/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.5530\n",
      "Epoch 6: loss improved from 5.64298 to 5.55303, saving model to next_words.h5\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 5.5530\n",
      "Epoch 7/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.4030\n",
      "Epoch 7: loss improved from 5.55303 to 5.40295, saving model to next_words.h5\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 5.4030\n",
      "Epoch 8/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 5.1810\n",
      "Epoch 8: loss improved from 5.40295 to 5.18099, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 5.1810\n",
      "Epoch 9/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.9269\n",
      "Epoch 9: loss improved from 5.18099 to 4.92692, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 4.9269\n",
      "Epoch 10/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.6934\n",
      "Epoch 10: loss improved from 4.92692 to 4.69336, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 424ms/step - loss: 4.6934\n",
      "Epoch 11/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.4892\n",
      "Epoch 11: loss improved from 4.69336 to 4.48916, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 4.4892\n",
      "Epoch 12/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.2825\n",
      "Epoch 12: loss improved from 4.48916 to 4.28247, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 449ms/step - loss: 4.2825\n",
      "Epoch 13/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 4.0567\n",
      "Epoch 13: loss improved from 4.28247 to 4.05672, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 4.0567\n",
      "Epoch 14/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.8518\n",
      "Epoch 14: loss improved from 4.05672 to 3.85182, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 441ms/step - loss: 3.8518\n",
      "Epoch 15/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.6305\n",
      "Epoch 15: loss improved from 3.85182 to 3.63049, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 466ms/step - loss: 3.6305\n",
      "Epoch 16/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.4482\n",
      "Epoch 16: loss improved from 3.63049 to 3.44824, saving model to next_words.h5\n",
      "64/64 [==============================] - 32s 497ms/step - loss: 3.4482\n",
      "Epoch 17/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.2590\n",
      "Epoch 17: loss improved from 3.44824 to 3.25899, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 469ms/step - loss: 3.2590\n",
      "Epoch 18/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.0683\n",
      "Epoch 18: loss improved from 3.25899 to 3.06832, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 431ms/step - loss: 3.0683\n",
      "Epoch 19/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.8614\n",
      "Epoch 19: loss improved from 3.06832 to 2.86135, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 476ms/step - loss: 2.8614\n",
      "Epoch 20/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.6721\n",
      "Epoch 20: loss improved from 2.86135 to 2.67211, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 439ms/step - loss: 2.6721\n",
      "Epoch 21/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.4818\n",
      "Epoch 21: loss improved from 2.67211 to 2.48180, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 2.4818\n",
      "Epoch 22/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.2667\n",
      "Epoch 22: loss improved from 2.48180 to 2.26673, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 425ms/step - loss: 2.2667\n",
      "Epoch 23/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.0867\n",
      "Epoch 23: loss improved from 2.26673 to 2.08667, saving model to next_words.h5\n",
      "64/64 [==============================] - 35s 546ms/step - loss: 2.0867\n",
      "Epoch 24/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9129\n",
      "Epoch 24: loss improved from 2.08667 to 1.91287, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 447ms/step - loss: 1.9129\n",
      "Epoch 25/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.7240\n",
      "Epoch 25: loss improved from 1.91287 to 1.72399, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 493ms/step - loss: 1.7240\n",
      "Epoch 26/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.5623\n",
      "Epoch 26: loss improved from 1.72399 to 1.56231, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 423ms/step - loss: 1.5623\n",
      "Epoch 27/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.4091\n",
      "Epoch 27: loss improved from 1.56231 to 1.40910, saving model to next_words.h5\n",
      "64/64 [==============================] - 32s 498ms/step - loss: 1.4091\n",
      "Epoch 28/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.2348\n",
      "Epoch 28: loss improved from 1.40910 to 1.23481, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 484ms/step - loss: 1.2348\n",
      "Epoch 29/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.1272\n",
      "Epoch 29: loss improved from 1.23481 to 1.12718, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 466ms/step - loss: 1.1272\n",
      "Epoch 30/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.0201\n",
      "Epoch 30: loss improved from 1.12718 to 1.02010, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 468ms/step - loss: 1.0201\n",
      "Epoch 31/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8836\n",
      "Epoch 31: loss improved from 1.02010 to 0.88361, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 457ms/step - loss: 0.8836\n",
      "Epoch 32/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.8350\n",
      "Epoch 32: loss improved from 0.88361 to 0.83504, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 459ms/step - loss: 0.8350\n",
      "Epoch 33/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7589\n",
      "Epoch 33: loss improved from 0.83504 to 0.75895, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 430ms/step - loss: 0.7589\n",
      "Epoch 34/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6808\n",
      "Epoch 34: loss improved from 0.75895 to 0.68076, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 437ms/step - loss: 0.6808\n",
      "Epoch 35/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6245\n",
      "Epoch 35: loss improved from 0.68076 to 0.62455, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 440ms/step - loss: 0.6245\n",
      "Epoch 36/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5941\n",
      "Epoch 36: loss improved from 0.62455 to 0.59406, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 460ms/step - loss: 0.5941\n",
      "Epoch 37/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5377\n",
      "Epoch 37: loss improved from 0.59406 to 0.53766, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 439ms/step - loss: 0.5377\n",
      "Epoch 38/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4972\n",
      "Epoch 38: loss improved from 0.53766 to 0.49715, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 441ms/step - loss: 0.4972\n",
      "Epoch 39/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4657\n",
      "Epoch 39: loss improved from 0.49715 to 0.46570, saving model to next_words.h5\n",
      "64/64 [==============================] - 32s 495ms/step - loss: 0.4657\n",
      "Epoch 40/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4579\n",
      "Epoch 40: loss improved from 0.46570 to 0.45789, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 477ms/step - loss: 0.4579\n",
      "Epoch 41/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4236\n",
      "Epoch 41: loss improved from 0.45789 to 0.42364, saving model to next_words.h5\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.4236\n",
      "Epoch 42/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4046\n",
      "Epoch 42: loss improved from 0.42364 to 0.40458, saving model to next_words.h5\n",
      "64/64 [==============================] - 29s 447ms/step - loss: 0.4046\n",
      "Epoch 43/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3913\n",
      "Epoch 43: loss improved from 0.40458 to 0.39132, saving model to next_words.h5\n",
      "64/64 [==============================] - 30s 467ms/step - loss: 0.3913\n",
      "Epoch 44/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3585\n",
      "Epoch 44: loss improved from 0.39132 to 0.35849, saving model to next_words.h5\n",
      "64/64 [==============================] - 32s 508ms/step - loss: 0.3585\n",
      "Epoch 45/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3507\n",
      "Epoch 45: loss improved from 0.35849 to 0.35075, saving model to next_words.h5\n",
      "64/64 [==============================] - 31s 484ms/step - loss: 0.3507\n",
      "Epoch 46/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3187\n",
      "Epoch 46: loss improved from 0.35075 to 0.31872, saving model to next_words.h5\n",
      "64/64 [==============================] - 28s 430ms/step - loss: 0.3187\n",
      "Epoch 47/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3243\n",
      "Epoch 47: loss did not improve from 0.31872\n",
      "64/64 [==============================] - 28s 431ms/step - loss: 0.3243\n",
      "Epoch 48/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3253\n",
      "Epoch 48: loss did not improve from 0.31872\n",
      "64/64 [==============================] - 27s 418ms/step - loss: 0.3253\n",
      "Epoch 49/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3217\n",
      "Epoch 49: loss did not improve from 0.31872\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.3217\n",
      "Epoch 50/50\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3098\n",
      "Epoch 50: loss improved from 0.31872 to 0.30984, saving model to next_words.h5\n",
      "64/64 [==============================] - 33s 514ms/step - loss: 0.3098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20aa72f64f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f5ce56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1 to speech and 2 to type the text:2\n",
      "Enter your line: one requires carbohydrates and\n",
      "['requires', 'carbohydrates', 'and']\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "children\n",
      "Enter your line: vitamin D rich food\n",
      "['i', 'rich', 'food']\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "and\n",
      "Enter your line: the human beings are\n",
      "['human', 'beings', 'are']\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "individual\n",
      "Enter your line: for survival in\n",
      "['for', 'survival', 'in']\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "the\n",
      "Enter your line: nature for what\n",
      "['nature', 'for', 'what']\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "and\n",
      "Enter your line: naure fot diet\n",
      "['nature', 'fot', 'diet']\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "of\n",
      "Enter your line: 0\n",
      "Execution completed.....\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "import speech_recognition\n",
    "import pyttsx3\n",
    "import pyaudio\n",
    "import speech_recognition as sr\n",
    "#calling spellcheck function\n",
    "spell=SpellChecker()\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "\n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "  print(predicted_word)\n",
    "  return predicted_word\n",
    "\n",
    "n=int(input(\"Enter 1 to speech and 2 to type the text:\"))\n",
    "if n==1:\n",
    "    recognizer = sr.Recognizer()\n",
    "    while True:\n",
    "        try:\n",
    "            with sr.Microphone() as mic:\n",
    "                recognizer.adjust_for_ambient_noise(mic, duration=0.2)\n",
    "                audio = recognizer.listen(mic)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "                text = text.lower()\n",
    "                print(\"Recognized text:\", text)\n",
    "                words=word_tokenize(text)\n",
    "                corrected_words=[]\n",
    "                for word in words:\n",
    "                    corrected_word=spell.correction(word)\n",
    "                    corrected_words.append(corrected_word)\n",
    "                correct_words=\" \".join(corrected_words)\n",
    "                if correct_words==\"stop\":\n",
    "                    print(\"Execution completed...\")\n",
    "                    break\n",
    "                else:\n",
    "                    try:\n",
    "                        correct_words=correct_words.split(\" \")\n",
    "                        correct_words=correct_words[-3:]\n",
    "                        print(correct_words)\n",
    "                        Predict_Next_Words(model,tokenizer,correct_words)\n",
    "                    except Exception as e:\n",
    "                        print(\"Error occured: \",e)\n",
    "                        continue\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "elif n==2:    \n",
    "    while(True):\n",
    "        text = input(\"Enter your line: \")\n",
    "        words=word_tokenize(text)\n",
    "        corrected_words=[]\n",
    "        for word in words:\n",
    "            corrected_word=spell.correction(word)\n",
    "            corrected_words.append(corrected_word)\n",
    "        correct_words=\" \".join(corrected_words)\n",
    "        if correct_words == \"0\":\n",
    "            print(\"Execution completed.....\")\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                correct_words = correct_words.split(\" \")\n",
    "                correct_words = correct_words[-3:]\n",
    "                print(correct_words)\n",
    "                Predict_Next_Words(model, tokenizer, correct_words)\n",
    "            except Exception as e:\n",
    "                print(\"Error occurred: \",e)\n",
    "                continue\n",
    "else:\n",
    "    print(\"Enter valid choices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78b2bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497d1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffb1607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x282b7f23250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('trained_model.h5')\n",
    "model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
